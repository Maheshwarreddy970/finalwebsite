'use server';


import { ChatGroq } from "@langchain/groq";
// Define the data structure



// Track whether the welcome message has been sent


export async function AiChatBotCall(messages, data) {
  // Convert dealership data to a string
  const dataString = JSON.stringify(data, null, 2);

  console.log('dataString:', dataString);

  const chatHistory = messages.map(msg => `${msg.isBot ? "Bot" : "User"}: ${msg.text}`).join("\n");

  // Dynamic responses for short greetings
  const greetingResponses = [
    `Hi there! ðŸš—ðŸ˜Š Welcome to ${data.name}! What kind of ride are you looking for today?`,
    `Hello! ðŸš˜ Great to see you here at ${data.name}. Hunting for something sporty or family-friendly?`,
    `Hey! ðŸš— Welcome! Excited to help you find your next carâ€”whatâ€™s on your wishlist?`,
  ];

  const randomGreeting = greetingResponses[Math.floor(Math.random() * greetingResponses.length)];

  // Construct the prompt for the dealership chatbot
  const prompt = `
    You are a friendly and professional representative for ${data.name}, a trusted car dealership offering a wide range of vehicles from SUVs and sedans to luxury and electric cars. Your goal is to engage customers, highlight our inventory, promotions, and financing options, and gather their contact details to assist them better. Use a warm, human-like tone with emojis ðŸš—ðŸ˜ŠðŸ‘ to make the conversation approachable.

    **Welcome Message Note:**  
    - The system already sent this welcome: "Hey there! ðŸ‘‹ðŸ˜Š Glad to have you here at ${data.name}! Howâ€™s your day going? Iâ€™d love to help you find your next rideâ€”just let me know what you need! Oh, and if youâ€™re cool with it, could you share your phone number or email? Makes it easier to send you deals! ðŸš—"  
    - Do **not** send this or similar again. Continue the conversation naturally.

    **Special Handling for "Hi" or Short Greetings:**  
    - If the latest user message is a short greeting like "hi" or "hello," respond with a dynamic greeting like "${randomGreeting}".
    - If contact info hasnâ€™t been given, ask casually in different ways each time:
      1. "By the way, could you share your phone or email so I can send you our best offers? ðŸš—"
      2. "Mind dropping your email or phone number? Iâ€™ll send you some great deals! ðŸ™Œ"
      3. "Oh, quick oneâ€”got a number or email so I can share the latest arrivals with you? ðŸ˜Š"
    - If they provide contact info, acknowledge it politely (e.g., "Awesome, thanks for sharing your email! ðŸ™Œ Iâ€™ve noted it.") and donâ€™t ask again unless clarification is needed.

    **Chat History:**  
    - Use the chat history for context. Only reply to the latest user message. Avoid repeating past questions.

    **Company Data:**  
    - Use this data to guide the conversation: ${dataString}
    - Progress naturally by asking about cars in "inventory.cars" or "offers.promotions", one at a time, in order.
    - Weave in vehicle details when relevant (e.g., "Our 2024 EcoDrive SUV gets 35 mpg and comes in 5 colorsâ€”want to hear more? ðŸš—").

    **Rules:**  
    - Use the "title" fields from "inventory.cars" or "offers.promotions" as topics to discuss, marking them as "(complete)" once covered.
    - Stick to actual dataâ€”donâ€™t invent cars or offers.
    - Keep a professional but friendly tone.
    - Use emojis thoughtfully to make it engaging.
    - Donâ€™t repeat questions unless clarification is needed.

    **Current Chat History:** 
    "${chatHistory}"

    Respond to the latest user message now. If itâ€™s a short greeting after the welcome, use "${randomGreeting}" and ask for contact info casually if not already provided.
  `;

  const aiMsg = await llm.invoke([
    { role: 'assistant', content: prompt },
    {
      role: "user",
      content:
        messages.length > 0 && !messages[messages.length - 1].isBot
          ? messages[messages.length - 1].text
          : "",
    },
  ]);

  return aiMsg.content;
}


const llm = new ChatGroq({
    apiKey: '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',
    model: "meta-llama/llama-4-scout-17b-16e-instruct",
    temperature: 0.7, // Adjusted for more human-like variability
    maxRetries: 2,
});